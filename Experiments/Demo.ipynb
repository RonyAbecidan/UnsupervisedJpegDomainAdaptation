{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from simulations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before reading that notebook please follow the instructions of the file [INSTALL.md](../INSTALL.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - How to launch a simulation ?\n",
    "\n",
    "- All you need is to precise some hyperparameters relative to the experiment in a yaml config file. Please find below the list of hyperparameters you have to give according to the setup (note that the config `example.yaml` contains already the structure to comply with) :\n",
    "\n",
    "| Name of the hyperparameter | Description                                                                                | Default value (ours)                                                                                                               |\n",
    "|----------------------------|--------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| seed                       | The seed used to make the training reproducible                                            | 2021                                                                                                                               |\n",
    "| N_fold                     | The number of fold you use for your cross validation                                       | 3                                                                                                                                  |\n",
    "| im_size                    | The size of the patches used for the training phases                                       | 128 |\n",
    "| setup                      | The setup you consider for your experiment (SrcOnly, Mix or Update)                                                | 'SrcOnly'                                                                                                                          |\n",
    "| precisions                 | Some precisions about the experiments (if None deduced from source_path and target_path)           | s=[source]_t=[target]                                                                                                                     |\n",
    "| source->nb_source_max              | The maximal number of patches you want to use for the source during training               | 10**(8)                                                                                                                            |\n",
    "| source->filename                | The filename of your source domain                                                  | 'source-none.hdf5'                                                                                                                 |\n",
    "| source->name                | Name of the source domain (deduced from source->filename, no need to add it)                                       | 'source-none'                                                                                                                      |\n",
    "| target->nb_target_max              | The maximal number of patches you want to use for the target during training               | 10**(8)                                                                                                                            |\n",
    "| target->filename               | The filename of your target domain                                                  | 'target-qf(5).hdf5'                                                                                                                |\n",
    "| target->name                | Name of the target domain (deduce from target->filename, no need to add it)                                        | 'target-qf(5)'                                                                                                                     |\n",
    "| training->save_at_each_epoch         | if True, for your first fold only, the weights of the detector will be saved at each epoch | true                                                                                                                               |\n",
    "| training->max_epochs                 | The maximal number of epochs for the training phases                                       | 30                                                                                                                                 |\n",
    "| training->earlystop_patience         | The maximal number of epochs we wait before the earlystopping                              | 5                                                                                                                                  |\n",
    "| training->lr                         | The initial learning rate for our training phases                                          | 0.0001                                                                                                                             |\n",
    "| training->batch_size           | The size of the batch size used during the training phases                                 | 128                                                                                                                                |\n",
    "| eval->batch_size            | The size of the batch size used during the evaluation phases                               | 512                                                                                                                                |\n",
    "| eval->domain_filenames               | The filenames of the domains used for the evaluation phases                             | [\"target-qf(5).hdf5\", \"target-qf(10).hdf5\", \"target-qf(20).hdf5\", \"target-qf(50).hdf5\", \"target-qf(100).hdf5\", \"target-none.hdf5\"] |\n",
    "| eval->domain_names               | The name of the domains for the evaluation phases (deduced from domain_filenames, no need to add it)               | [\"qf(5)\", \"qf(10)\", \"qf(20)\", \"qf(50)\", \"qf(100)\", \"none\"]                                                                         |\n",
    "\n",
    "\n",
    "For what follows, note that the source and target filenames are stored in the list `sources` and `targets` implicitly imported above via `simulations.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sources)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Example 1 : We want to test the Experiment  `SrcOnly_s=none_t=qf(5)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate('./Results/SrcOnly-s=none_t=qf(5)/hyperparameters-SrcOnly-s=none_t=qf(5).yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Example 2 : We want to test the Experiment  `TgtOnly_s=qf(5)_t=qf(5)`**\n",
    "\n",
    "*Technically, the TgtOnly setup is just a SrcOnly setup with an other source. Hence, we didn't explicitly considered a TgtOnly setup in our code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate('./Results/SrcOnly-s=qf(5)_t=qf(5)/hyperparameters-SrcOnly-s=qf(5)_t=qf(5).yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Example 3 : We want to test the Experiment  `Update(sigma=8)_s=None_t=qf(5)`**\n",
    "\n",
    "*For that we need to precise also the bandwiths parameter at the level of each final dense layer. This is possible with an extra key 'sigmas' that you need to add in the config file*\n",
    "\n",
    "*You can also precise with the key 'precisions' that you choose a specific bandwith for your experiment so that it appeared in the names of the folder and the file containing the results*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate('./Results/Update-s=none_t=qf(5)/hyperparameters-Update-s=none_t=qf(5).yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II -  Can I reproduce the nice gif you gave in the Readme to see what is going one for each experiment ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course ! Setting the key `save_at_each_epoch` to True enables to save the weights of your detector at each epoch for the first training phase (first fold). \n",
    "When you have all the weights, you can use the function below. \n",
    "\n",
    "It requires use to install imageio doing `pip install imageio`. \n",
    "\n",
    "Moreover, you need before to obtain a batch and its associated labels from your domain\n",
    "\n",
    "To do so you can simply do something like below :\n",
    "\n",
    "```\n",
    " my_set=MyDataset(f'{your_domain_path}',key1=f'test_0',key2=f'l_test_0')\n",
    " my_dataloader=DataLoader(my_set, batch_size=512, shuffle=True)\n",
    "\n",
    " torch.manual_seed(10)\n",
    " it=iter(my_dataloader)\n",
    " batch,labels=next(it)\n",
    "```\n",
    "\n",
    "Pay attention that you also need to precise again the hyperparameters that you used for your experiment with a config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif(hyperparameters_config_file,batch,labels):\n",
    "    hyperparameters=initialize_hyperparameters(hyperparameters_config_file)\n",
    "    my_detector=ForgeryDetector(hyperparameters)\n",
    "    my_detector.to(device)\n",
    "    \n",
    "    for i in range(0,25):\n",
    "        \n",
    "        my_detector.load_state_dict(torch.load(f'./Results/{my_detector.folder_path}/{hyperparameters['setup']}-{i+1}.pt'))\n",
    "        my_detector.eval()\n",
    "        \n",
    "        embedding=(my_detector(batch)).cpu().detach().numpy()\n",
    "        \n",
    "        plt.figure(figsize=(24,8))\n",
    "\n",
    "        norm0=(my_detector(batch[labels==0]).view(-1)).cpu().std().detach().numpy()\n",
    "        norm1=(my_detector(batch[labels==1]).view(-1)).cpu().std().detach().numpy()\n",
    "        plt.hist((embedding[labels==0]).reshape(-1)/norm0,alpha=0.5,label='real',bins=50,color='#1ABC9C',density=True);\n",
    "        plt.hist((embedding[labels==1]).reshape(-1)/norm1,alpha=0.5,label='forged',bins=50,color='#186A3B',density=True)\n",
    "        plt.plot([0,0],[0,1],color='black',lw=5,linestyle='--',alpha=0.5)\n",
    "        plt.title(f'Distribution of the final embeddings from your domain ({hyperparameters['setup']},epoch {i})');\n",
    "        plt.legend()\n",
    "        plt.xlim(-5,5)\n",
    "        plt.ylim(0,1)\n",
    "        \n",
    "        plt.savefig(f'{i}.png');\n",
    "        plt.close()\n",
    "\n",
    "    with imageio.get_writer(f'Evolution.gif', mode='I') as writer:\n",
    "        for filename in np.array([10*[f'{i}.png'] for i in range(0,30)]).reshape(-1):\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uda2",
   "language": "python",
   "name": "uda2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
