{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from simulations import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before reading that notebook please follow the instructions of the file [INSTALL.md](../INSTALL.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - How to launch a simulation ?\n",
    "\n",
    "- All you need is to precise some hyperparameters relative to the experiment. Please find below the list of hyperparameters you have to give according to the setup (note that the function `initialize_hyperparameters` can simplify this task) :\n",
    "\n",
    "| Name of the hyperparameter | Description                                                                                | Default value (ours)                                                                                                               |\n",
    "|----------------------------|--------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| seed                       | The seed used to make the training reproducible                                            | 2021                                                                                                                               |\n",
    "| N_fold                     | The number of fold you use for your cross validation                                       | 3                                                                                                                                  |\n",
    "| im_size                    | The size of the patches used for the training phases                                       | 128                                                                                                                                |\n",
    "| max_epochs                 | The maximal number of epochs for the training phases                                       | 30                                                                                                                                 |\n",
    "| earlystop_patience         | The maximal number of epochs we wait before the earlystopping                              | 5                                                                                                                                  |\n",
    "| lr                         | The initial learning rate for our training phases                                          | 0.0001                                                                                                                             |\n",
    "| train_batch_size           | The size of the batch size used during the training phases                                 | 128                                                                                                                                |\n",
    "| eval_batch_size            | The size of the batch size used during the evaluation phases                               | 512                                                                                                                                |\n",
    "| detector_name              | The name of the forgery detector you use                                                   | 'Bayar'                                                                                                                            |\n",
    "| source_path                | The filename of your source domain                                                  | 'source-none.hdf5'                                                                                                                 |\n",
    "| target_path                | The filename of your target domain                                                  | 'target-qf(5).hdf5'                                                                                                                |\n",
    "| source_name                | Name of the source domain (deduced from source_path)                                       | 'source-none'                                                                                                                      |\n",
    "| target_name                | Name of the target domain (deduce from target_path)                                        | 'target-qf(5)'                                                                                                                     |\n",
    "| setup                      | The setup you consider for your experiment                                                 | 'SrcOnly'                                                                                                                          |\n",
    "| domain paths               | The filenames of the domains used for the evaluation phases                             | [\"target-qf(5).hdf5\", \"target-qf(10).hdf5\", \"target-qf(20).hdf5\", \"target-qf(50).hdf5\", \"target-qf(100).hdf5\", \"target-none.hdf5\"] |\n",
    "| domain_names               | The name of the domains for the evaluation phases (deduced from domain_path)               | [\"qf(5)\", \"qf(10)\", \"qf(20)\", \"qf(50)\", \"qf(100)\", \"none\"]                                                                         |\n",
    "| nb_source_max              | The maximal number of patches you want to use for the source during training               | 10**(8)                                                                                                                            |\n",
    "| nb_target_max              | The maximal number of patches you want to use for the target during training               | 10**(8)                                                                                                                            |\n",
    "| save_at_each_epoch         | if True, for your first fold only, the weights of the detector will be saved at each epoch | true                                                                                                                               |\n",
    "| precisions                 | Some precisions about the experiments (deduced from source_path and target_path)           | s=none_t=qf(5)                                                                                                                     |\n",
    "\n",
    "For what follows, note that the source and target filenames are stored in the list `sources` and `targets` implicitly imported above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sources)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example 1 : We want to test the Experiment  `SrcOnly_s=none_t=qf(5)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters=initialize_hyperparameters(source_path=sources[2],target_path=target[0],eval_domains=targets,details=None,save_at_each_epoch=False,setup='SrcOnly')\n",
    "simulate(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example 2 : We want to test the Experiment  `TgtOnly_s=qf(5)_t=qf(5)`\n",
    "\n",
    "*Technically, the TgtOnly setup is just a SrcOnly setup with an other source. Hence, we didn't explicitly considered a TgtOnly setup in our code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters=initialize_hyperparameters(source_path=sources[0],target_path=target[0],eval_domains=targets,details=None,save_at_each_epoch=False,setup='SrcOnly')\n",
    "simulate(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example 3 : We want to test the Experiment  `Update(sigma=8)_s=None_t=qf(5)`\n",
    "\n",
    "*For that we need to precise also the bandwiths parameter at the level of each final dense layer. This is possible with an extra hyperparameters 'sigmas' that you need to add*\n",
    "\n",
    "*You can also precise in 'details' that you choose a specific bandwith for your experiment so that it appeared in the name of the file containing the results*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters=initialize_hyperparameters(source_path=sources[2],target_path=target[0],eval_domains=targets,details='sigma=8',save_at_each_epoch=False,setup='Update')\n",
    "hyperparameters['sigmas']=[8,8,8]\n",
    "simulate(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example 4 : We want to test the Experiment  `Update(sigmas=[2,3,4])_s=None_t=qf(5)_N_t=1000 `\n",
    "\n",
    "*For that we need to precise also the bandwiths parameter at the level of each final dense layer and change the default value of nb_target_max.*\n",
    "\n",
    "*You can also precise in 'details' that you choose specific bandwiths for your experiment so that it appeared in the name of the file containing the results*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters=initialize_hyperparameters(source_path=sources[2],target_path=target[0],eval_domains=targets,details='sigma=8',save_at_each_epoch=False,setup='Update')\n",
    "hyperparameters['sigmas']=[2,3,4]\n",
    "hyperparameters['nb_target_max']=1000\n",
    "simulate(hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II -  Can I reproduce the nice gif you gave in the Readme to see what is going one for each experiment ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course ! Setting the key `save_at_each_epoch` to True enables to save the weights of your detector at each epoch for the first training phase (first fold). \n",
    "When you have all the weights, you can use the function below. \n",
    "\n",
    "It requires use to install imageio doing `pip install imageio`. \n",
    "\n",
    "Moreover, you need before to obtain a batch and its associated labels from your domain\n",
    "\n",
    "To do so you can simply do something like below :\n",
    "\n",
    "```\n",
    " my_set=MyDataset(f'{your_domain_path}',key1=f'test_0',key2=f'l_test_0')\n",
    " my_dataloader=DataLoader(my_set, batch_size=512, shuffle=True)\n",
    "\n",
    " torch.manual_seed(10)\n",
    " it=iter(my_dataloader)\n",
    " batch,labels=next(it)\n",
    "```\n",
    "\n",
    "Pay attention that you also need to precise again the hyperparameters that you used for your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif(hyperparameters,batch,labels):\n",
    "    my_detector=ForgeryDetector(hyperparameters)\n",
    "    my_detector.to(device)\n",
    "    \n",
    "    for i in range(0,25):\n",
    "        \n",
    "        my_detector.load_state_dict(torch.load(f'./Results/{my_detector.folder_path}/{hyperparameters['setup']}-{i+1}.pt'))\n",
    "        my_detector.eval()\n",
    "        \n",
    "        embedding=(my_detector(batch)).cpu().detach().numpy()\n",
    "        \n",
    "        plt.figure(figsize=(24,8))\n",
    "\n",
    "        norm0=(my_detector(batch[labels==0]).view(-1)).cpu().std().detach().numpy()\n",
    "        norm1=(my_detector(batch[labels==1]).view(-1)).cpu().std().detach().numpy()\n",
    "        plt.hist((embedding[labels==0]).reshape(-1)/norm0,alpha=0.5,label='real',bins=50,color='#1ABC9C',density=True);\n",
    "        plt.hist((embedding[labels==1]).reshape(-1)/norm1,alpha=0.5,label='forged',bins=50,color='#186A3B',density=True)\n",
    "        plt.plot([0,0],[0,1],color='black',lw=5,linestyle='--',alpha=0.5)\n",
    "        plt.title(f'Distribution of the final embeddings from your domain ({hyperparameters['setup']},epoch {i})');\n",
    "        plt.legend()\n",
    "        plt.xlim(-5,5)\n",
    "        plt.ylim(0,1)\n",
    "        \n",
    "        plt.savefig(f'{i}.png');\n",
    "        plt.close()\n",
    "\n",
    "    with imageio.get_writer(f'Evolution.gif', mode='I') as writer:\n",
    "        for filename in np.array([10*[f'{i}.png'] for i in range(0,30)]).reshape(-1):\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wifs2021]",
   "language": "python",
   "name": "conda-env-wifs2021-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
